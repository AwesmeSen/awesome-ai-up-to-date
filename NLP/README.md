## Attention
- May 2, 2019 - [Attention Explained - Stanford NLP Course](https://www.youtube.com/watch?v=XXtpJxZBa2c&feature=youtu.be&t=3721)


## Neural Networks
- Jan 13, 2020 - [NN concepts for NLP](https://github.com/neulab/nn4nlp-concepts)

## Domain Adaptation
- Jan 13, 2020 - [Multi-Source Domain Adaptation for Text Classification via DistanceNet-Bandits](https://arxiv.org/abs/2001.04362)

# Transformers
- Aug 18, 2019 -[Transformers from scratch](http://www.peterbloem.nl/blog/transformers))
- Aug 20, 2019 -[LXMERT: Learning Cross-Modality Encoder Representations from Transformers](https://arxiv.org/abs/1908.07490)
- Aug 23, 2019 -[Making Transformer networks simpler and more efficient ](https://ai.facebook.com/blog/making-transformer-networks-simpler-and-more-efficient/)

## Transfer Learning
- Aug 18, 2019 - [The State of Transfer Learning in NLP](https://ruder.io/state-of-transfer-learning-in-nlp/)
- Mar 28,2019 -[Distilling Task-Specific Knowledge from BERT intoSimple Neural Networks](https://arxiv.org/pdf/1903.12136.pdf)
- Aug 28, 2019 -[Smaller, faster, cheaper, lighter: Introducing DistilBERT, a distilled version of BERT](https://medium.com/huggingface/distilbert-8cf3380435b5)

## Contextual Embeddings
- June, 2018 -[Deep contextualized word representations](https://www.aclweb.org/anthology/N18-1202.pdf)

## Multi-Task Learning
- Mar 22, 2019 -[Massive Multi-Task Learning with Snorkel MeTaL: Bringing More Supervision to Bear](https://dawn.cs.stanford.edu/2019/03/22/glue/)

## Implementation
- [Putting Cutting-Edge Modern NLP into Practice](https://docs.google.com/presentation/d/1I5iF_Iu-WF5U8K0CBDd1VGyxqEsOFH509eeW4-nvSXc/edit#slide=id.g625c52cb18_0_122)

## Lifelong Learning
- Nov 16, 2018 - [Towards Training Recurrent Neural Networks for Lifelong Learning](https://arxiv.org/abs/1811.07017)
