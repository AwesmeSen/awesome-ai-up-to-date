## Attention
- May 2, 2019 - [Attention Explained - Stanford NLP Course](https://www.youtube.com/watch?v=XXtpJxZBa2c&feature=youtu.be&t=3721)

## BERT
- [Extracting different senses of polysemic words from BERT](https://medium.com/@leslie_huang/automatic-extraction-of-word-senses-from-deep-contextualized-word-embeddings-2f09f16e820)
- Jan 24, 2020 - [How to train BERT with limited GPU RAM (PyTorch)](https://www.youtube.com/watch?v=Q2fT-lANdVQ)
- Jan 17, 2020 - [How to fine tune BERT for NER](https://gab41.lab41.org/how-to-fine-tune-bert-for-named-entity-recognition-2257b5e5ce7e)
- Jan 7, 2020 - [The Dark Secrets of BERT](https://text-machine-lab.github.io/blog/2020/bert-secrets/)

## Neural Networks
- Jan 13, 2020 - [NN concepts for NLP](https://github.com/neulab/nn4nlp-concepts)

## Domain Adaptation
- Jan 13, 2020 - [Multi-Source Domain Adaptation for Text Classification via DistanceNet-Bandits](https://arxiv.org/abs/2001.04362)

# Transformers
- Jan 22, 2020 - [Evolution of Representations in the Transformer](https://www.youtube.com/watch?v=h5N7sbAKBhA)
- Aug 18, 2019 -[Transformers from scratch](http://www.peterbloem.nl/blog/transformers))
- Aug 20, 2019 -[LXMERT: Learning Cross-Modality Encoder Representations from Transformers](https://arxiv.org/abs/1908.07490)
- Aug 23, 2019 -[Making Transformer networks simpler and more efficient ](https://ai.facebook.com/blog/making-transformer-networks-simpler-and-more-efficient/)

## Transfer Learning
- Aug 18, 2019 - [The State of Transfer Learning in NLP](https://ruder.io/state-of-transfer-learning-in-nlp/)
- Mar 28,2019 -[Distilling Task-Specific Knowledge from BERT intoSimple Neural Networks](https://arxiv.org/pdf/1903.12136.pdf)
- Aug 28, 2019 -[Smaller, faster, cheaper, lighter: Introducing DistilBERT, a distilled version of BERT](https://medium.com/huggingface/distilbert-8cf3380435b5)

## Contextual Embeddings
- June, 2018 -[Deep contextualized word representations](https://www.aclweb.org/anthology/N18-1202.pdf)

## Multi-Task Learning
- Mar 22, 2019 -[Massive Multi-Task Learning with Snorkel MeTaL: Bringing More Supervision to Bear](https://dawn.cs.stanford.edu/2019/03/22/glue/)

## Implementation
- [Putting Cutting-Edge Modern NLP into Practice](https://docs.google.com/presentation/d/1I5iF_Iu-WF5U8K0CBDd1VGyxqEsOFH509eeW4-nvSXc/edit#slide=id.g625c52cb18_0_122)

## Lifelong Learning
- Nov 16, 2018 - [Towards Training Recurrent Neural Networks for Lifelong Learning](https://arxiv.org/abs/1811.07017)

## Compositionality
- Jan, 2020 - [Pull out all the stops: Textual analysis via punctuation sequences](https://arxiv.org/abs/1901.00519v2)
- Aug, 2019 - [The compositionality of neural networks: integrating symbolism and connectionism](https://arxiv.org/abs/1908.08351)
